{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient representation of multidimensional arrays.\n",
    "### Last modification (11.04.2018)\n",
    "\n",
    "\n",
    "In this tutorial we provide a theoretical backgound on efficient representation of multidimensional arrays and show how these data structures are integrated into [hottbox](https://github.com/hottbox/hottbox) through **TensorCPD**, **TensorTKD** and **TensorTT** classes.\n",
    "\n",
    "More details on **TensorCPD**, **TensorTKD** and **TensorTT** classes can be found on the [documentation page](https://hottbox.github.io/stable/api/hottbox.core.html#module-hottbox.core).\n",
    "\n",
    "> **Note:** this tutorial assumes that you are familiar with the basics of tensor algebra and the corresponding conventional notation.  If you are new to this area, the required background is covered in our [introductory notebook](https://github.com/hottbox/hottbox-tutorials/blob/master/1_N-dimensional_arrays_and_Tensor_class.ipynb).\n",
    "\n",
    "**Author:** Ilya Kisil - ilyakisil@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hottbox.core.structures import Tensor, TensorCPD, TensorTKD, TensorTT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![storage_complexity](./images/storage_complexity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outer product, rank-1 tensor and definitions of rank of a multi-dimensional array.\n",
    "\n",
    "## Outer product\n",
    "The central operator in tensor analysis is the outer product (sometimes refered to as the tensor product). \n",
    "Consider tensors $\\mathbf{\\underline{A}} \\in \\mathbb{R}^{I_1 \\times \\cdots \\times I_N}$ and $\\mathbf{\\underline{B}}  \\in \\mathbb{R}^{J_1 \\times \\cdots \\times J_M}$, then  their outer product yeilds a tensor of higher order then both of them:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    \\mathbf{\\underline{A}} \\circ \\mathbf{\\underline{B}} &= \\mathbf{\\underline{C}} \\in \\mathbb{R}^{I_1 \\times \\cdots \\times I_N \\times J_1 \\times \\cdots \\times J_M} \\\\\n",
    "    a_{i_1,\\dots,i_N}b_{j_1,\\dots,j_M} &= c_{i_1,\\dots,i_N,j_1,\\dots,j_M} \n",
    "\\end{aligned}    \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Most of the time we deal with the outer product of vectors, which significanlty simplifies the general form expressed above and establishes one the of the most fundamenatal definitions.\n",
    "A tensor of order $N$ is said to be of **rank-1** if it can be represented as an outer product of $N$ vectors. The figure below illustrates an example of rank-1 tensor $\\mathbf{\\underline{X}}$ and provides intuition of how operation of outer product is computed:\n",
    "\n",
    "![outerproduct](./images/outerproduct_3.png)\n",
    "\n",
    "There are several forms of the rank of N-dimensional arrays each of which is accosiated with a representation of a tensor in a particular form:\n",
    "\n",
    "1. Kryskal rank $\\rightarrow$ canonical polyadic form.\n",
    "\n",
    "- Multi-linear rank $\\rightarrow$ tucker form.\n",
    "\n",
    "- TT rank $\\rightarrow$ tensor train form.\n",
    "\n",
    "> **Note:** The Kryskal rank and the rank of tensor are often time used interchangeably\n",
    "\n",
    "Each of this representations has the correposing class: **``TensorCPD``**, **``TensorTKD``**,\n",
    "**``TensorTT``**. All of them come with almost identical API except of obejct creation and,\n",
    "as a result, the names for some attributes. But before, we can proceed, it is crucial to \n",
    "get acquainted with the following definitions.\n",
    "\n",
    "\n",
    "## Kryskal rank\n",
    "\n",
    "The rank of a tensor $\\mathbf{\\underline{X}}$ is defined as the smallest number of rank-one tensors that generate $\\mathbf{\\underline{X}}$ as their linear combination. \n",
    "The figure below illustrates a tensor $\\mathbf{\\underline{X}}$ of rank $R$.\n",
    "\n",
    "![cpd_as_rank_one](./images/cpd_as_rank_one.png)\n",
    "\n",
    "\n",
    "## Multi-linear rank\n",
    "\n",
    "The multi-linear rank of a tensor $\\mathbf{\\underline{X}} \\in \\mathbb{R}^{I_1 \\times \\cdots \\times I_N}$ is the \n",
    "$N$-tuple $(R_1, \\dots, R_N)$ where each $R_n$ is the rank of the subspace spanned by mode-$n$ \n",
    "fibers, i.e. $R_n = \\text{rank} \\big( \\mathbf{X}_{(n)} \\big)$.\n",
    "\n",
    "> **Note:** for a tensor of order $N$ the values $R_1, R_2, \\dots , R_N$ are not necessarily the\n",
    "same, whereas, for matrices (tensors of order 2) the equality $R_1 = R_2$ always holds, where \n",
    "$R_1$ and $R_2$ are the matrix column rank and row rank respectively.\n",
    "\n",
    "\n",
    "## **TT rank (COMMING SOON)**\n",
    "\n",
    "> **!!!  NEED TO FILL IN  !!!**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical polydiac form and **TensorCPD** class\n",
    "\n",
    "![tensorcpd](./images/TensorCPD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The canonical polyadic (CP) form represents a tensor as linear combination of rank-1 tensors. For a third order tensor or rank $R$ it can be expressed as follows:\n",
    "\n",
    "$$\\mathbf{\\underline{X}} = \\sum_{r=1}^R \\lambda_{r} \\cdot \\mathbf{a}_r \\circ \\mathbf{b}_r \\circ \\mathbf{c}_r$$\n",
    "\n",
    "The vectors $\\mathbf{a}_r, \\mathbf{b}_r$ and $\\mathbf{c}_r$ are oftentime combined into corresponding **factor matrices**:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\Big[ \\mathbf{a}_1 \\cdots \\mathbf{a}_R \\Big] \\quad\n",
    "\\mathbf{B} = \\Big[ \\mathbf{b}_1 \\cdots \\mathbf{b}_R \\Big] \\quad\n",
    "\\mathbf{C} = \\Big[ \\mathbf{c}_1 \\cdots \\mathbf{c}_R \\Big] \\quad\n",
    "$$\n",
    "\n",
    "Thus, if we employ the mode-$n$ product, the canonical polyadic representation takes form:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\underline{X}} = \\mathbf{\\underline{\\Lambda}} \\times_1 \\mathbf{A} \\times_2 \\mathbf{B} \\times_3 \\mathbf{C} = \\Big[\\mathbf{\\underline{\\Lambda}}; \\mathbf{A}, \\mathbf{B}, \\mathbf{C} \\Big]\n",
    "$$\n",
    "where the elements on the super-diagonal of $\\mathbf{\\underline{\\Lambda}}$ are occupied by the values\n",
    "$\\lambda_r$ and all other equal to zero.\n",
    "\n",
    "In **``hottbox``** this form is available through the **``TensorCPD``** class.\n",
    "In order to create such object, you need to pass a list of factor matrices (2d ``numpy`` arrays) and a vector of values (as 1d ``numpy`` array) for the main diagonal:\n",
    "\n",
    "```python\n",
    "tensor_cpd = TensorCPD(fmat=[A, B, C], core_values=values)\n",
    "```\n",
    "\n",
    "> **Note:** all matrices should have the same number of columns and be equal to the length of ``values``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J, K = 5, 6, 7  # define shape of the tensor in full form\n",
    "R = 4  # define Kryskal rank of a tensor in CP form \n",
    "\n",
    "A = np.arange(I * R).reshape(I, R)\n",
    "B = np.arange(J * R).reshape(J, R)\n",
    "C = np.arange(K * R).reshape(K, R)\n",
    "values = np.arange(R)\n",
    "# values = np.random.rand(R)\n",
    "\n",
    "tensor_cpd = TensorCPD(fmat=[A, B, C], core_values=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we passed only the values for the super-diagonal, the core tensor of the CP \n",
    "representation still can be accessed by calling the corresponding property:\n",
    "\n",
    "```python\n",
    "tensor_cpd.core\n",
    "```\n",
    "This return an object of the **``Tensor``** class with the **``values``** placed on its super-diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3.\n",
      "The sizes of its modes are (4, 4, 4) respectively.\n",
      "It consists of 64 elemetns.\n",
      "Its Frobenious norm = 3.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 2., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 3.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(tensor_cpd.core))\n",
    "print('This tensor is of order {}.'.format(tensor_cpd.core.order))\n",
    "print('The sizes of its modes are {} respectively.'.format(tensor_cpd.core.shape))\n",
    "print('It consists of {} elemetns.'.format(tensor_cpd.core.size))\n",
    "print('Its Frobenious norm = {:.2f}'.format(tensor_cpd.core.frob_norm))\n",
    "tensor_cpd.core.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert **``TensorCPD``** into the full representation, simply call: \n",
    "\n",
    "```python\n",
    "tensor_cpd.reconstruct\n",
    "```\n",
    "\n",
    "This return an object of the **``Tensor``** class with N-dimensional array calculated as \n",
    "described above and being assinged to the **``data``** attibute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3.\n",
      "The sizes of its modes are (5, 6, 7) respectively.\n",
      "It consists of 210 elemetns.\n",
      "Its Frobenious norm = 238601.50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[   98.,   242.,   386.,   530.,   674.,   818.,   962.],\n",
       "        [  242.,   610.,   978.,  1346.,  1714.,  2082.,  2450.],\n",
       "        [  386.,   978.,  1570.,  2162.,  2754.,  3346.,  3938.],\n",
       "        [  530.,  1346.,  2162.,  2978.,  3794.,  4610.,  5426.],\n",
       "        [  674.,  1714.,  2754.,  3794.,  4834.,  5874.,  6914.],\n",
       "        [  818.,  2082.,  3346.,  4610.,  5874.,  7138.,  8402.]],\n",
       "\n",
       "       [[  242.,   610.,   978.,  1346.,  1714.,  2082.,  2450.],\n",
       "        [  610.,  1586.,  2562.,  3538.,  4514.,  5490.,  6466.],\n",
       "        [  978.,  2562.,  4146.,  5730.,  7314.,  8898., 10482.],\n",
       "        [ 1346.,  3538.,  5730.,  7922., 10114., 12306., 14498.],\n",
       "        [ 1714.,  4514.,  7314., 10114., 12914., 15714., 18514.],\n",
       "        [ 2082.,  5490.,  8898., 12306., 15714., 19122., 22530.]],\n",
       "\n",
       "       [[  386.,   978.,  1570.,  2162.,  2754.,  3346.,  3938.],\n",
       "        [  978.,  2562.,  4146.,  5730.,  7314.,  8898., 10482.],\n",
       "        [ 1570.,  4146.,  6722.,  9298., 11874., 14450., 17026.],\n",
       "        [ 2162.,  5730.,  9298., 12866., 16434., 20002., 23570.],\n",
       "        [ 2754.,  7314., 11874., 16434., 20994., 25554., 30114.],\n",
       "        [ 3346.,  8898., 14450., 20002., 25554., 31106., 36658.]],\n",
       "\n",
       "       [[  530.,  1346.,  2162.,  2978.,  3794.,  4610.,  5426.],\n",
       "        [ 1346.,  3538.,  5730.,  7922., 10114., 12306., 14498.],\n",
       "        [ 2162.,  5730.,  9298., 12866., 16434., 20002., 23570.],\n",
       "        [ 2978.,  7922., 12866., 17810., 22754., 27698., 32642.],\n",
       "        [ 3794., 10114., 16434., 22754., 29074., 35394., 41714.],\n",
       "        [ 4610., 12306., 20002., 27698., 35394., 43090., 50786.]],\n",
       "\n",
       "       [[  674.,  1714.,  2754.,  3794.,  4834.,  5874.,  6914.],\n",
       "        [ 1714.,  4514.,  7314., 10114., 12914., 15714., 18514.],\n",
       "        [ 2754.,  7314., 11874., 16434., 20994., 25554., 30114.],\n",
       "        [ 3794., 10114., 16434., 22754., 29074., 35394., 41714.],\n",
       "        [ 4834., 12914., 20994., 29074., 37154., 45234., 53314.],\n",
       "        [ 5874., 15714., 25554., 35394., 45234., 55074., 64914.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_full = tensor_cpd.reconstruct\n",
    "\n",
    "print(type(tensor_full))\n",
    "print('This tensor is of order {}.'.format(tensor_full.order))\n",
    "print('The sizes of its modes are {} respectively.'.format(tensor_full.shape))\n",
    "print('It consists of {} elemetns.'.format(tensor_full.size))\n",
    "print('Its Frobenious norm = {:.2f}'.format(tensor_full.frob_norm))\n",
    "\n",
    "tensor_full.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker form and **TensorTKD** class\n",
    "\n",
    "![tensortkd](./images/TensorTKD.png)\n",
    "\n",
    "For a tensor $\\mathbf{\\underline{X}} \\in \\mathbb{R}^{I \\times J \\times K}$ illustrated above, the tucker form\n",
    "represents it as a dense core tensor $\\mathbf{\\underline{G}}$ with multi-linear rank ($Q, R, P$) and a set of\n",
    "factor matrices $\\mathbf{A} \\in \\mathbb{R}^{I \\times Q}, \\mathbf{B} \\in \\mathbb{R}^{J \\times R}$ and $\\mathbf{C} \\in\n",
    "\\mathbb{R}^{K \\times P}$.\n",
    "\n",
    "The tucker form of a tensor is closely related to the CP form and can be expressed through a \n",
    "sequence of mode-$n$ products in a similar way.\n",
    "\n",
    "$$\n",
    "\\mathbf{\\underline{X}} = \\mathbf{\\underline{G}} \\times_1 \\mathbf{A} \\times_2 \\mathbf{B} \\times_3 \\mathbf{C} = \\Big[\\mathbf{\\underline{G}}; \\mathbf{A}, \\mathbf{B}, \\mathbf{C} \\Big]\n",
    "$$\n",
    "\n",
    "In **``hottbox``** this form is available through the **``TensorTKD``** class.\n",
    "In order to create such object, you need to pass a list of factor matrices (2d ``numpy`` arrays) and values for the core tensor (as n-dimensional ``numpy`` array):\n",
    "\n",
    "```python\n",
    "tensor_tkd = TensorTKD(fmat=[A, B, C], core_values=values)\n",
    "```\n",
    "\n",
    "> **Note:** the number of columns in each of the factor matrices should be the same as the corresponding size of the ``numpy`` array with the values for the core tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J, K = 5, 6, 7  # define shape of the tensor in full form\n",
    "Q, R, P = 2, 3, 4  # define multi-linear rank of the tensor in Tucker form\n",
    "\n",
    "A = np.arange(I * Q).reshape(I, Q)\n",
    "B = np.arange(J * R).reshape(J, R)\n",
    "C = np.arange(K * P).reshape(K, P)\n",
    "values = np.arange(Q * R * P).reshape(Q, R, P)\n",
    "# values = np.random.rand(Q * R * P).reshape(Q, R, P)\n",
    "\n",
    "tensor_tkd = TensorTKD(fmat=[A, B, C], core_values=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert **``TensorTKD``** into the full representation, simply call: \n",
    "\n",
    "```python\n",
    "tensor_tkd.reconstruct\n",
    "```\n",
    "\n",
    "This return an object of the **``Tensor``** class with N-dimensional array calculated as \n",
    "described above and being assinged to the **``data``** attibute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3.\n",
      "The sizes of its modes are (5, 6, 7) respectively.\n",
      "It consists of 210 elemetns.\n",
      "Its Frobenious norm = 3535670.11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[    378,    1346,    2314,    3282,    4250,    5218,    6186],\n",
       "        [   1368,    4856,    8344,   11832,   15320,   18808,   22296],\n",
       "        [   2358,    8366,   14374,   20382,   26390,   32398,   38406],\n",
       "        [   3348,   11876,   20404,   28932,   37460,   45988,   54516],\n",
       "        [   4338,   15386,   26434,   37482,   48530,   59578,   70626],\n",
       "        [   5328,   18896,   32464,   46032,   59600,   73168,   86736]],\n",
       "\n",
       "       [[   1458,    5146,    8834,   12522,   16210,   19898,   23586],\n",
       "        [   5112,   17944,   30776,   43608,   56440,   69272,   82104],\n",
       "        [   8766,   30742,   52718,   74694,   96670,  118646,  140622],\n",
       "        [  12420,   43540,   74660,  105780,  136900,  168020,  199140],\n",
       "        [  16074,   56338,   96602,  136866,  177130,  217394,  257658],\n",
       "        [  19728,   69136,  118544,  167952,  217360,  266768,  316176]],\n",
       "\n",
       "       [[   2538,    8946,   15354,   21762,   28170,   34578,   40986],\n",
       "        [   8856,   31032,   53208,   75384,   97560,  119736,  141912],\n",
       "        [  15174,   53118,   91062,  129006,  166950,  204894,  242838],\n",
       "        [  21492,   75204,  128916,  182628,  236340,  290052,  343764],\n",
       "        [  27810,   97290,  166770,  236250,  305730,  375210,  444690],\n",
       "        [  34128,  119376,  204624,  289872,  375120,  460368,  545616]],\n",
       "\n",
       "       [[   3618,   12746,   21874,   31002,   40130,   49258,   58386],\n",
       "        [  12600,   44120,   75640,  107160,  138680,  170200,  201720],\n",
       "        [  21582,   75494,  129406,  183318,  237230,  291142,  345054],\n",
       "        [  30564,  106868,  183172,  259476,  335780,  412084,  488388],\n",
       "        [  39546,  138242,  236938,  335634,  434330,  533026,  631722],\n",
       "        [  48528,  169616,  290704,  411792,  532880,  653968,  775056]],\n",
       "\n",
       "       [[   4698,   16546,   28394,   40242,   52090,   63938,   75786],\n",
       "        [  16344,   57208,   98072,  138936,  179800,  220664,  261528],\n",
       "        [  27990,   97870,  167750,  237630,  307510,  377390,  447270],\n",
       "        [  39636,  138532,  237428,  336324,  435220,  534116,  633012],\n",
       "        [  51282,  179194,  307106,  435018,  562930,  690842,  818754],\n",
       "        [  62928,  219856,  376784,  533712,  690640,  847568, 1004496]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_full = tensor_tkd.reconstruct\n",
    "\n",
    "print(type(tensor_full))\n",
    "print('This tensor is of order {}.'.format(tensor_full.order))\n",
    "print('The sizes of its modes are {} respectively.'.format(tensor_full.shape))\n",
    "print('It consists of {} elemetns.'.format(tensor_full.size))\n",
    "print('Its Frobenious norm = {:.2f}'.format(tensor_full.frob_norm))\n",
    "\n",
    "tensor_full.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor train form and **TensorTT** class\n",
    "\n",
    "![tensortt](./images/TensorTT.png)\n",
    "## **Theoretical background (COMMING SOON)**\n",
    "\n",
    "> **!!!  NEED TO FILL IN  !!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **``hottbox``** this form is available through the **``TensorTT``** class.\n",
    "In order to create such object, you need to pass a list of values (as ``numpy`` arrays) for \n",
    "cores the shape of a tensor in full form (as ``tuple``):\n",
    "\n",
    "```python\n",
    "tensor_tt = TensorTT(core_values=values, full_shape=shape)\n",
    "```\n",
    "\n",
    "> **Note:** it is very likely that the argument ``full_shape`` will be removed soon. Check\n",
    "the [CHANGELOG](https://github.com/hottbox/hottbox/blob/master/CHANGELOG.md) of **``hottbox``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J, K = 5, 6, 7  # define shape of the tensor in full form\n",
    "shape =  (I, J, K)\n",
    "R1, R2 = 2, 3  # define tt rank of the tensor in Tensor train form\n",
    "\n",
    "values_1 = np.arange(I * R1).reshape(I, R1)\n",
    "values_2 = np.arange(R1 * J * R2).reshape(R1, J, R2)\n",
    "values_3 = np.arange(R2 * K).reshape(R2, K)\n",
    "values = [values_1, values_2, values_3]\n",
    "\n",
    "tensor_tt = TensorTT(core_values=values, full_shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert **``TensorTT``** into the full representation, simply call: \n",
    "\n",
    "```python\n",
    "tensor_tt.reconstruct\n",
    "```\n",
    "\n",
    "This return an object of the **``Tensor``** class with N-dimensional array calculated as \n",
    "described above and being assinged to the **``data``** attibute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3.\n",
      "The sizes of its modes are (5, 6, 7) respectively.\n",
      "It consists of 210 elemetns.\n",
      "Its Frobenious norm = 91247.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  413,   470,   527,   584,   641,   698,   755],\n",
       "        [  476,   542,   608,   674,   740,   806,   872],\n",
       "        [  539,   614,   689,   764,   839,   914,   989],\n",
       "        [  602,   686,   770,   854,   938,  1022,  1106],\n",
       "        [  665,   758,   851,   944,  1037,  1130,  1223],\n",
       "        [  728,   830,   932,  1034,  1136,  1238,  1340]],\n",
       "\n",
       "       [[ 1309,  1486,  1663,  1840,  2017,  2194,  2371],\n",
       "        [ 1624,  1846,  2068,  2290,  2512,  2734,  2956],\n",
       "        [ 1939,  2206,  2473,  2740,  3007,  3274,  3541],\n",
       "        [ 2254,  2566,  2878,  3190,  3502,  3814,  4126],\n",
       "        [ 2569,  2926,  3283,  3640,  3997,  4354,  4711],\n",
       "        [ 2884,  3286,  3688,  4090,  4492,  4894,  5296]],\n",
       "\n",
       "       [[ 2205,  2502,  2799,  3096,  3393,  3690,  3987],\n",
       "        [ 2772,  3150,  3528,  3906,  4284,  4662,  5040],\n",
       "        [ 3339,  3798,  4257,  4716,  5175,  5634,  6093],\n",
       "        [ 3906,  4446,  4986,  5526,  6066,  6606,  7146],\n",
       "        [ 4473,  5094,  5715,  6336,  6957,  7578,  8199],\n",
       "        [ 5040,  5742,  6444,  7146,  7848,  8550,  9252]],\n",
       "\n",
       "       [[ 3101,  3518,  3935,  4352,  4769,  5186,  5603],\n",
       "        [ 3920,  4454,  4988,  5522,  6056,  6590,  7124],\n",
       "        [ 4739,  5390,  6041,  6692,  7343,  7994,  8645],\n",
       "        [ 5558,  6326,  7094,  7862,  8630,  9398, 10166],\n",
       "        [ 6377,  7262,  8147,  9032,  9917, 10802, 11687],\n",
       "        [ 7196,  8198,  9200, 10202, 11204, 12206, 13208]],\n",
       "\n",
       "       [[ 3997,  4534,  5071,  5608,  6145,  6682,  7219],\n",
       "        [ 5068,  5758,  6448,  7138,  7828,  8518,  9208],\n",
       "        [ 6139,  6982,  7825,  8668,  9511, 10354, 11197],\n",
       "        [ 7210,  8206,  9202, 10198, 11194, 12190, 13186],\n",
       "        [ 8281,  9430, 10579, 11728, 12877, 14026, 15175],\n",
       "        [ 9352, 10654, 11956, 13258, 14560, 15862, 17164]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_full = tensor_tt.reconstruct\n",
    "\n",
    "print(type(tensor_full))\n",
    "print('This tensor is of order {}.'.format(tensor_full.order))\n",
    "print('The sizes of its modes are {} respectively.'.format(tensor_full.shape))\n",
    "print('It consists of {} elemetns.'.format(tensor_full.size))\n",
    "print('Its Frobenious norm = {:.2f}'.format(tensor_full.frob_norm))\n",
    "\n",
    "tensor_full.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
