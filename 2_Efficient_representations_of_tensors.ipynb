{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient representation of multidimensional arrays.\n",
    "### Last modification (13.05.2018)\n",
    "\n",
    "\n",
    "In this tutorial we provide a theoretical backgound on efficient representation of multidimensional arrays and show how these data structures are integrated into [hottbox](https://github.com/hottbox/hottbox) through **TensorCPD**, **TensorTKD** and **TensorTT** classes.\n",
    "\n",
    "More details on **TensorCPD**, **TensorTKD** and **TensorTT** classes can be found on the [documentation page](https://hottbox.github.io/stable/api/hottbox.core.html#module-hottbox.core).\n",
    "\n",
    "> **Note:** this tutorial assumes that you are familiar with the basics of tensor algebra and the corresponding conventional notation.  If you are new to this area, the required background is covered in our [introductory notebook](https://github.com/hottbox/hottbox-tutorials/blob/master/1_N-dimensional_arrays_and_Tensor_class.ipynb).\n",
    "\n",
    "**Requirements:** ``hottbox>=0.1.2``\n",
    "\n",
    "**Author:** Ilya Kisil - ilyakisil@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hottbox.core import Tensor, TensorCPD, TensorTKD, TensorTT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![storage_complexity](./images/storage_complexity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outer product, rank-1 tensor and definitions of rank of a multi-dimensional array.\n",
    "\n",
    "## Outer product\n",
    "The central operator in tensor analysis is the outer product (sometimes refered to as the tensor product). \n",
    "Consider tensors $\\mathbf{\\underline{A}} \\in \\mathbb{R}^{I_1 \\times \\cdots \\times I_N}$ and $\\mathbf{\\underline{B}}  \\in \\mathbb{R}^{J_1 \\times \\cdots \\times J_M}$, then  their outer product yeilds a tensor of higher order then both of them:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    \\mathbf{\\underline{A}} \\circ \\mathbf{\\underline{B}} &= \\mathbf{\\underline{C}} \\in \\mathbb{R}^{I_1 \\times \\cdots \\times I_N \\times J_1 \\times \\cdots \\times J_M} \\\\\n",
    "    a_{i_1,\\dots,i_N}b_{j_1,\\dots,j_M} &= c_{i_1,\\dots,i_N,j_1,\\dots,j_M} \n",
    "\\end{aligned}    \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Most of the time we deal with the outer product of vectors, which significanlty simplifies the general form expressed above and establishes one the of the most fundamenatal definitions.\n",
    "A tensor of order $N$ is said to be of **rank-1** if it can be represented as an outer product of $N$ vectors. The figure below illustrates an example of rank-1 tensor $\\mathbf{\\underline{X}}$ and provides intuition of how operation of outer product is computed:\n",
    "\n",
    "![outerproduct](./images/outerproduct_3.png)\n",
    "\n",
    "There are several forms of the rank of N-dimensional arrays each of which is accosiated with a representation of a tensor in a particular form:\n",
    "\n",
    "1. Kryskal rank $\\rightarrow$ canonical polyadic form.\n",
    "\n",
    "- Multi-linear rank $\\rightarrow$ tucker form.\n",
    "\n",
    "- TT rank $\\rightarrow$ tensor train form.\n",
    "\n",
    "> **Note:** The Kryskal rank and the rank of tensor are often time used interchangeably\n",
    "\n",
    "Each of this representations has the correposing class: **``TensorCPD``**, **``TensorTKD``**,\n",
    "**``TensorTT``**. All of them come with almost identical API except of obejct creation and,\n",
    "as a result, the names for some attributes. But before, we can proceed, it is crucial to \n",
    "get acquainted with the following definitions.\n",
    "\n",
    "\n",
    "## Kryskal rank\n",
    "\n",
    "The rank of a tensor $\\mathbf{\\underline{X}}$ is defined as the smallest number of rank-one tensors that generate $\\mathbf{\\underline{X}}$ as their linear combination. \n",
    "The figure below illustrates a tensor $\\mathbf{\\underline{X}}$ of rank $R$.\n",
    "\n",
    "![cpd_as_rank_one](./images/cpd_as_rank_one.png)\n",
    "\n",
    "\n",
    "## Multi-linear rank\n",
    "\n",
    "The multi-linear rank of a tensor $\\mathbf{\\underline{X}} \\in \\mathbb{R}^{I_1 \\times \\cdots \\times I_N}$ is the \n",
    "$N$-tuple $(R_1, \\dots, R_N)$ where each $R_n$ is the rank of the subspace spanned by mode-$n$ \n",
    "fibers, i.e. $R_n = \\text{rank} \\big( \\mathbf{X}_{(n)} \\big)$.\n",
    "\n",
    "> **Note:** for a tensor of order $N$ the values $R_1, R_2, \\dots , R_N$ are not necessarily the\n",
    "same, whereas, for matrices (tensors of order 2) the equality $R_1 = R_2$ always holds, where \n",
    "$R_1$ and $R_2$ are the matrix column rank and row rank respectively.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical polydiac form and **TensorCPD** class\n",
    "\n",
    "![tensorcpd](./images/TensorCPD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The canonical polyadic (CP) form represents a tensor as linear combination of rank-1 tensors. For a third order tensor or rank $R$ it can be expressed as follows:\n",
    "\n",
    "$$\\mathbf{\\underline{X}} = \\sum_{r=1}^R \\lambda_{r} \\cdot \\mathbf{a}_r \\circ \\mathbf{b}_r \\circ \\mathbf{c}_r$$\n",
    "\n",
    "The vectors $\\mathbf{a}_r, \\mathbf{b}_r$ and $\\mathbf{c}_r$ are oftentime combined into corresponding **factor matrices**:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\Big[ \\mathbf{a}_1 \\cdots \\mathbf{a}_R \\Big] \\quad\n",
    "\\mathbf{B} = \\Big[ \\mathbf{b}_1 \\cdots \\mathbf{b}_R \\Big] \\quad\n",
    "\\mathbf{C} = \\Big[ \\mathbf{c}_1 \\cdots \\mathbf{c}_R \\Big] \\quad\n",
    "$$\n",
    "\n",
    "Thus, if we employ the mode-$n$ product, the canonical polyadic representation takes form:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\underline{X}} = \\mathbf{\\underline{\\Lambda}} \\times_1 \\mathbf{A} \\times_2 \\mathbf{B} \\times_3 \\mathbf{C} = \\Big[\\mathbf{\\underline{\\Lambda}}; \\mathbf{A}, \\mathbf{B}, \\mathbf{C} \\Big]\n",
    "$$\n",
    "where the elements on the super-diagonal of $\\mathbf{\\underline{\\Lambda}}$ are occupied by the values\n",
    "$\\lambda_r$ and all other equal to zero.\n",
    "\n",
    "In **``hottbox``** this form is available through the **``TensorCPD``** class.\n",
    "In order to create such object, you need to pass a list of factor matrices (2d ``numpy`` arrays) and a vector of values (as 1d ``numpy`` array) for the main diagonal:\n",
    "\n",
    "```python\n",
    "tensor_cpd = TensorCPD(fmat=[A, B, C], core_values=values)\n",
    "```\n",
    "\n",
    "> **Note:** all matrices should have the same number of columns and be equal to the length of ``values``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J, K = 5, 6, 7  # define shape of the tensor in full form\n",
    "R = 4  # define Kryskal rank of a tensor in CP form \n",
    "\n",
    "A = np.arange(I * R).reshape(I, R)\n",
    "B = np.arange(J * R).reshape(J, R)\n",
    "C = np.arange(K * R).reshape(K, R)\n",
    "values = np.arange(R)\n",
    "# values = np.random.rand(R)\n",
    "\n",
    "tensor_cpd = TensorCPD(fmat=[A, B, C], core_values=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of factor matrices is stored in **`_fmat`** attribute (placeholder) which can (should) be accessed through the correspodning property **`fmat`**.\n",
    "\n",
    "It is slightly different for the core values.\n",
    "Even though we passed the values for the super-diagonal and they are stored in **`_core_values`** attribute (placeholder), they cannot (should not) be accessed directly. \n",
    "Instead, they are used to create a core tensor of the CP representation when the corresponding property is called:\n",
    "\n",
    "```python\n",
    "tensor_cpd.core\n",
    "```\n",
    "This returns an object of the **``Tensor``** class with the **``_core_values``** placed on its super-diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor matrices\n",
      "Mode-0 factor matrix is of shape (5, 4)\n",
      "Mode-1 factor matrix is of shape (6, 4)\n",
      "Mode-2 factor matrix is of shape (7, 4)\n",
      "\n",
      "Core tensor\n",
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3, consists of 64 elements and its Frobenious norm = 3.74.\n",
      "Sizes and names of its modes are (4, 4, 4) and {0: 'mode-0', 1: 'mode-1', 2: 'mode-2'} respectively.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  2.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  3.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Factor matrices')\n",
    "for mode, fmat in enumerate(tensor_cpd.fmat):\n",
    "    print('Mode-{} factor matrix is of shape {}'.format(mode, fmat.shape))\n",
    "    \n",
    "print('\\nCore tensor')\n",
    "print(type(tensor_cpd.core))\n",
    "tensor_cpd.core.describe()\n",
    "tensor_cpd.core.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert **``TensorCPD``** into the full representation, simply call: \n",
    "\n",
    "```python\n",
    "tensor_cpd.reconstruct\n",
    "```\n",
    "\n",
    "This return an object of the **``Tensor``** class with N-dimensional array calculated as \n",
    "described above and being assinged to the **``_data``** attibute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3, consists of 210 elements and its Frobenious norm = 238601.50.\n",
      "Sizes and names of its modes are (5, 6, 7) and {0: 'mode-0', 1: 'mode-1', 2: 'mode-2'} respectively.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[    98.,    242.,    386.,    530.,    674.,    818.,    962.],\n",
       "        [   242.,    610.,    978.,   1346.,   1714.,   2082.,   2450.],\n",
       "        [   386.,    978.,   1570.,   2162.,   2754.,   3346.,   3938.],\n",
       "        [   530.,   1346.,   2162.,   2978.,   3794.,   4610.,   5426.],\n",
       "        [   674.,   1714.,   2754.,   3794.,   4834.,   5874.,   6914.],\n",
       "        [   818.,   2082.,   3346.,   4610.,   5874.,   7138.,   8402.]],\n",
       "\n",
       "       [[   242.,    610.,    978.,   1346.,   1714.,   2082.,   2450.],\n",
       "        [   610.,   1586.,   2562.,   3538.,   4514.,   5490.,   6466.],\n",
       "        [   978.,   2562.,   4146.,   5730.,   7314.,   8898.,  10482.],\n",
       "        [  1346.,   3538.,   5730.,   7922.,  10114.,  12306.,  14498.],\n",
       "        [  1714.,   4514.,   7314.,  10114.,  12914.,  15714.,  18514.],\n",
       "        [  2082.,   5490.,   8898.,  12306.,  15714.,  19122.,  22530.]],\n",
       "\n",
       "       [[   386.,    978.,   1570.,   2162.,   2754.,   3346.,   3938.],\n",
       "        [   978.,   2562.,   4146.,   5730.,   7314.,   8898.,  10482.],\n",
       "        [  1570.,   4146.,   6722.,   9298.,  11874.,  14450.,  17026.],\n",
       "        [  2162.,   5730.,   9298.,  12866.,  16434.,  20002.,  23570.],\n",
       "        [  2754.,   7314.,  11874.,  16434.,  20994.,  25554.,  30114.],\n",
       "        [  3346.,   8898.,  14450.,  20002.,  25554.,  31106.,  36658.]],\n",
       "\n",
       "       [[   530.,   1346.,   2162.,   2978.,   3794.,   4610.,   5426.],\n",
       "        [  1346.,   3538.,   5730.,   7922.,  10114.,  12306.,  14498.],\n",
       "        [  2162.,   5730.,   9298.,  12866.,  16434.,  20002.,  23570.],\n",
       "        [  2978.,   7922.,  12866.,  17810.,  22754.,  27698.,  32642.],\n",
       "        [  3794.,  10114.,  16434.,  22754.,  29074.,  35394.,  41714.],\n",
       "        [  4610.,  12306.,  20002.,  27698.,  35394.,  43090.,  50786.]],\n",
       "\n",
       "       [[   674.,   1714.,   2754.,   3794.,   4834.,   5874.,   6914.],\n",
       "        [  1714.,   4514.,   7314.,  10114.,  12914.,  15714.,  18514.],\n",
       "        [  2754.,   7314.,  11874.,  16434.,  20994.,  25554.,  30114.],\n",
       "        [  3794.,  10114.,  16434.,  22754.,  29074.,  35394.,  41714.],\n",
       "        [  4834.,  12914.,  20994.,  29074.,  37154.,  45234.,  53314.],\n",
       "        [  5874.,  15714.,  25554.,  35394.,  45234.,  55074.,  64914.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_full = tensor_cpd.reconstruct\n",
    "\n",
    "print(type(tensor_full))\n",
    "tensor_full.describe()\n",
    "tensor_full.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker form and **TensorTKD** class\n",
    "\n",
    "![tensortkd](./images/TensorTKD.png)\n",
    "\n",
    "For a tensor $\\mathbf{\\underline{X}} \\in \\mathbb{R}^{I \\times J \\times K}$ illustrated above, the tucker form\n",
    "represents it as a dense core tensor $\\mathbf{\\underline{G}}$ with multi-linear rank ($Q, R, P$) and a set of\n",
    "factor matrices $\\mathbf{A} \\in \\mathbb{R}^{I \\times Q}, \\mathbf{B} \\in \\mathbb{R}^{J \\times R}$ and $\\mathbf{C} \\in\n",
    "\\mathbb{R}^{K \\times P}$.\n",
    "\n",
    "The tucker form of a tensor is closely related to the CP form and can be expressed through a \n",
    "sequence of mode-$n$ products in a similar way.\n",
    "\n",
    "$$\n",
    "\\mathbf{\\underline{X}} = \\mathbf{\\underline{G}} \\times_1 \\mathbf{A} \\times_2 \\mathbf{B} \\times_3 \\mathbf{C} = \\Big[\\mathbf{\\underline{G}}; \\mathbf{A}, \\mathbf{B}, \\mathbf{C} \\Big]\n",
    "$$\n",
    "\n",
    "In **``hottbox``** this form is available through the **``TensorTKD``** class.\n",
    "In order to create such object, you need to pass a list of factor matrices (2d ``numpy`` arrays) and values for the core tensor (as n-dimensional ``numpy`` array):\n",
    "\n",
    "```python\n",
    "tensor_tkd = TensorTKD(fmat=[A, B, C], core_values=values)\n",
    "```\n",
    "\n",
    "> **Note:** the number of columns in each of the factor matrices should be the same as the corresponding size of the ``numpy`` array with the values for the core tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J, K = 5, 6, 7  # define shape of the tensor in full form\n",
    "Q, R, P = 2, 3, 4  # define multi-linear rank of the tensor in Tucker form\n",
    "\n",
    "A = np.arange(I * Q).reshape(I, Q)\n",
    "B = np.arange(J * R).reshape(J, R)\n",
    "C = np.arange(K * P).reshape(K, P)\n",
    "values = np.arange(Q * R * P).reshape(Q, R, P)\n",
    "# values = np.random.rand(Q * R * P).reshape(Q, R, P)\n",
    "\n",
    "tensor_tkd = TensorTKD(fmat=[A, B, C], core_values=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analogy with the **`TensorCPD`**, the list of factor matrices is stored in **`_fmat`** attribute (placeholder) which can (should) be accessed through the correspodning property **`fmat`**.\n",
    "\n",
    "Similarly, the values of the core tensor are stored in **`_core_values`** attribute (placeholder) and they cannot (should not) be accessed directly.\n",
    "Instead, they are used to create an obecjt of **`Tensor`** class, when the corresponding property is called:\n",
    "\n",
    "```python\n",
    "tensor_tkd.core\n",
    "```\n",
    "\n",
    "> **Note:** the core values occupy all data values of a core tensor, as opposed to **`TensorCPD`** class where they are placed on the main diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor matrices\n",
      "Mode-0 factor matrix is of shape (5, 2)\n",
      "Mode-1 factor matrix is of shape (6, 3)\n",
      "Mode-2 factor matrix is of shape (7, 4)\n",
      "\n",
      "Core tensor\n",
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3, consists of 24 elements and its Frobenious norm = 65.76.\n",
      "Sizes and names of its modes are (2, 3, 4) and {0: 'mode-0', 1: 'mode-1', 2: 'mode-2'} respectively.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Factor matrices')\n",
    "for mode, fmat in enumerate(tensor_tkd.fmat):\n",
    "    print('Mode-{} factor matrix is of shape {}'.format(mode, fmat.shape))\n",
    "    \n",
    "print('\\nCore tensor')\n",
    "print(type(tensor_tkd.core))\n",
    "tensor_tkd.core.describe()\n",
    "tensor_tkd.core.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert **``TensorTKD``** into the full representation, simply call: \n",
    "\n",
    "```python\n",
    "tensor_tkd.reconstruct\n",
    "```\n",
    "\n",
    "This return an object of the **``Tensor``** class with N-dimensional array calculated as \n",
    "described above and being assinged to the **``_data``** attibute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3, consists of 210 elements and its Frobenious norm = 3535670.11.\n",
      "Sizes and names of its modes are (5, 6, 7) and {0: 'mode-0', 1: 'mode-1', 2: 'mode-2'} respectively.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[    378,    1346,    2314,    3282,    4250,    5218,    6186],\n",
       "        [   1368,    4856,    8344,   11832,   15320,   18808,   22296],\n",
       "        [   2358,    8366,   14374,   20382,   26390,   32398,   38406],\n",
       "        [   3348,   11876,   20404,   28932,   37460,   45988,   54516],\n",
       "        [   4338,   15386,   26434,   37482,   48530,   59578,   70626],\n",
       "        [   5328,   18896,   32464,   46032,   59600,   73168,   86736]],\n",
       "\n",
       "       [[   1458,    5146,    8834,   12522,   16210,   19898,   23586],\n",
       "        [   5112,   17944,   30776,   43608,   56440,   69272,   82104],\n",
       "        [   8766,   30742,   52718,   74694,   96670,  118646,  140622],\n",
       "        [  12420,   43540,   74660,  105780,  136900,  168020,  199140],\n",
       "        [  16074,   56338,   96602,  136866,  177130,  217394,  257658],\n",
       "        [  19728,   69136,  118544,  167952,  217360,  266768,  316176]],\n",
       "\n",
       "       [[   2538,    8946,   15354,   21762,   28170,   34578,   40986],\n",
       "        [   8856,   31032,   53208,   75384,   97560,  119736,  141912],\n",
       "        [  15174,   53118,   91062,  129006,  166950,  204894,  242838],\n",
       "        [  21492,   75204,  128916,  182628,  236340,  290052,  343764],\n",
       "        [  27810,   97290,  166770,  236250,  305730,  375210,  444690],\n",
       "        [  34128,  119376,  204624,  289872,  375120,  460368,  545616]],\n",
       "\n",
       "       [[   3618,   12746,   21874,   31002,   40130,   49258,   58386],\n",
       "        [  12600,   44120,   75640,  107160,  138680,  170200,  201720],\n",
       "        [  21582,   75494,  129406,  183318,  237230,  291142,  345054],\n",
       "        [  30564,  106868,  183172,  259476,  335780,  412084,  488388],\n",
       "        [  39546,  138242,  236938,  335634,  434330,  533026,  631722],\n",
       "        [  48528,  169616,  290704,  411792,  532880,  653968,  775056]],\n",
       "\n",
       "       [[   4698,   16546,   28394,   40242,   52090,   63938,   75786],\n",
       "        [  16344,   57208,   98072,  138936,  179800,  220664,  261528],\n",
       "        [  27990,   97870,  167750,  237630,  307510,  377390,  447270],\n",
       "        [  39636,  138532,  237428,  336324,  435220,  534116,  633012],\n",
       "        [  51282,  179194,  307106,  435018,  562930,  690842,  818754],\n",
       "        [  62928,  219856,  376784,  533712,  690640,  847568, 1004496]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_full = tensor_tkd.reconstruct\n",
    "\n",
    "print(type(tensor_full))\n",
    "tensor_full.describe()\n",
    "tensor_full.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor train form and **TensorTT** class\n",
    "\n",
    "![tensortt](./images/TensorTT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor trains (TTs) are the simplest kinds of tensor networks, i.e. a decomposition of a high-order tensor in a set of sparsely interconnected lower-order tensors and factor matrices. Mathematically, an $N$-th order tensor $\\mathbf{\\underline{X}} \\in \\mathbb{R}^{I_1 \\times I_2 \\times \\cdots \\times I_N}$ can be expressed as a TT as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{\\underline{X}} = \\mathbf{A} \\times^1_2 \\mathbf{\\underline{G}}^{(1)}  \\times^1_3 \\mathbf{\\underline{G}}^{(2)}   \\times^1_3 \\cdots \\times^1_3 \\mathbf{\\underline{G}}^{(N-1)} \\times^1_3 \\mathbf{B} = \\Big[  \\mathbf{A}, \\mathbf{\\underline{G}}^{(1)}, \\mathbf{\\underline{G}}^{(2)}, \\cdots, \\mathbf{\\underline{G}}^{(N-1)}, \\mathbf{B}  \\Big]\n",
    "\\end{equation}\n",
    "\n",
    "Each element of a TT is generally referred to as $\\textit{core}$, and $\\mathbf{A} \\in \\mathbb{R}^{I_1 \\times R_1}$, $\\mathbf{B} \\in \\mathbb{R}^{R_{N-1}\\times I_N}$, $\\mathbf{\\underline{G}}^{(n)} \\in \\mathbb{R}^{R_n \\times I_{n+1} \\times R_{n+1}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **``hottbox``** this form is available through the **``TensorTT``** class.\n",
    "In order to create such object, you need to pass a list of values (as ``numpy`` arrays) for \n",
    "cores the shape of a tensor in full form (as ``tuple``):\n",
    "\n",
    "```python\n",
    "tensor_tt = TensorTT(core_values=values, ft_shape=shape)\n",
    "```\n",
    "\n",
    "> **Note:** it is very likely that the argument ``ft_shape`` will be removed soon. Check\n",
    "the [CHANGELOG](https://github.com/hottbox/hottbox/blob/master/CHANGELOG.md) of **``hottbox``**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TT-rank\n",
    "Given a TT decomposition of an $N$-th order tensor $\\mathbf{\\underline{X}} \\in \\mathbb{R}^{I_1 \\times I_2 \\times \\cdots \\times I_N}$, as $\\mathbf{\\underline{X}} = \\Big[  \\mathbf{A}, \\mathbf{\\underline{G}}^{(1)}, \\mathbf{\\underline{G}}^{(2)}, \\cdots, \\mathbf{\\underline{G}}^{(N-1)}, \\mathbf{B}  \\Big]$, with cores $\\mathbf{\\underline{G}}^{(n)} \\in \\mathbb{R}^{R_n \\times I_{n+1} \\times R_{n+1}}$, the tuple $(R_1, R_2, \\dots, R_{N-1})$ is called the TT-rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J, K = 5, 6, 7  # define shape of the tensor in full form\n",
    "shape =  (I, J, K)\n",
    "R1, R2 = 2, 3  # define tt rank of the tensor in Tensor train form\n",
    "\n",
    "values_1 = np.arange(I * R1).reshape(I, R1)\n",
    "values_2 = np.arange(R1 * J * R2).reshape(R1, J, R2)\n",
    "values_3 = np.arange(R2 * K).reshape(R2, K)\n",
    "values = [values_1, values_2, values_3]\n",
    "\n",
    "tensor_tt = TensorTT(core_values=values, ft_shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of core tensors is stored in **`_core_values`** attribute (placeholder) which can (should), but they cannot (should not) be accessed directly. Instead, they can be accessed all together via **`cores`** property which outputs a list where each entry from **`_core_values`** is converted to a **`Tensor`** class:\n",
    "\n",
    "```python\n",
    "tensor_tt.cores\n",
    "```\n",
    "\n",
    "> **Note:** All components of the Tensor Train representation are conventionally considered to be a core therefore, even matrices are objects of **`Tensor`** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCore tensor #0 of TT representation\n",
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 2, consists of 10 elements and its Frobenious norm = 16.88.\n",
      "Sizes and names of its modes are (5, 2) and {0: 'mode-0', 1: 'mode-1'} respectively.\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "\n",
      "\tCore tensor #1 of TT representation\n",
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3, consists of 36 elements and its Frobenious norm = 122.11.\n",
      "Sizes and names of its modes are (2, 6, 3) and {0: 'mode-0', 1: 'mode-1', 2: 'mode-2'} respectively.\n",
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]\n",
      "  [ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]\n",
      "  [30 31 32]\n",
      "  [33 34 35]]]\n",
      "\n",
      "\tCore tensor #2 of TT representation\n",
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 2, consists of 21 elements and its Frobenious norm = 53.57.\n",
      "Sizes and names of its modes are (3, 7) and {0: 'mode-0', 1: 'mode-1'} respectively.\n",
      "[[ 0  1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12 13]\n",
      " [14 15 16 17 18 19 20]]\n"
     ]
    }
   ],
   "source": [
    "for i, tt_core in enumerate(tensor_tt.cores):        \n",
    "    print('\\n\\tCore tensor #{} of TT representation'.format(i))    \n",
    "    print(type(tt_core))\n",
    "    tt_core.describe()\n",
    "    print(tt_core.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you what to access a specific core tensor of the TT representation, then it is more efficient to use a corresponding method which takes a positional number of desired core as input parameters\n",
    "\n",
    "```python\n",
    "tensor_tt.core(i=0)\n",
    "```\n",
    "\n",
    "> **Note:** this parameter should not exceed the order of TT representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCore tensor #0 of TT representation\n",
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 2, consists of 10 elements and its Frobenious norm = 16.88.\n",
      "Sizes and names of its modes are (5, 2) and {0: 'mode-0', 1: 'mode-1'} respectively.\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "\n",
      "\tCore tensor #1 of TT representation\n",
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3, consists of 36 elements and its Frobenious norm = 122.11.\n",
      "Sizes and names of its modes are (2, 6, 3) and {0: 'mode-0', 1: 'mode-1', 2: 'mode-2'} respectively.\n",
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]\n",
      "  [ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]\n",
      "  [30 31 32]\n",
      "  [33 34 35]]]\n",
      "\n",
      "\tCore tensor #2 of TT representation\n",
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 2, consists of 21 elements and its Frobenious norm = 53.57.\n",
      "Sizes and names of its modes are (3, 7) and {0: 'mode-0', 1: 'mode-1'} respectively.\n",
      "[[ 0  1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12 13]\n",
      " [14 15 16 17 18 19 20]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(tensor_tt.order):\n",
    "    tt_core = tensor_tt.core(i)\n",
    "    print('\\n\\tCore tensor #{} of TT representation'.format(i))    \n",
    "    print(type(tt_core))\n",
    "    tt_core.describe()\n",
    "    print(tt_core.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert **``TensorTT``** into the full representation, simply call: \n",
    "\n",
    "```python\n",
    "tensor_tt.reconstruct\n",
    "```\n",
    "\n",
    "This return an object of the **``Tensor``** class with N-dimensional array calculated as \n",
    "described above and being assinged to the **``_data``** attibute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'hottbox.core.structures.Tensor'>\n",
      "This tensor is of order 3, consists of 210 elements and its Frobenious norm = 91247.96.\n",
      "Sizes and names of its modes are (5, 6, 7) and {0: 'mode-0', 1: 'mode-1', 2: 'mode-2'} respectively.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  413,   470,   527,   584,   641,   698,   755],\n",
       "        [  476,   542,   608,   674,   740,   806,   872],\n",
       "        [  539,   614,   689,   764,   839,   914,   989],\n",
       "        [  602,   686,   770,   854,   938,  1022,  1106],\n",
       "        [  665,   758,   851,   944,  1037,  1130,  1223],\n",
       "        [  728,   830,   932,  1034,  1136,  1238,  1340]],\n",
       "\n",
       "       [[ 1309,  1486,  1663,  1840,  2017,  2194,  2371],\n",
       "        [ 1624,  1846,  2068,  2290,  2512,  2734,  2956],\n",
       "        [ 1939,  2206,  2473,  2740,  3007,  3274,  3541],\n",
       "        [ 2254,  2566,  2878,  3190,  3502,  3814,  4126],\n",
       "        [ 2569,  2926,  3283,  3640,  3997,  4354,  4711],\n",
       "        [ 2884,  3286,  3688,  4090,  4492,  4894,  5296]],\n",
       "\n",
       "       [[ 2205,  2502,  2799,  3096,  3393,  3690,  3987],\n",
       "        [ 2772,  3150,  3528,  3906,  4284,  4662,  5040],\n",
       "        [ 3339,  3798,  4257,  4716,  5175,  5634,  6093],\n",
       "        [ 3906,  4446,  4986,  5526,  6066,  6606,  7146],\n",
       "        [ 4473,  5094,  5715,  6336,  6957,  7578,  8199],\n",
       "        [ 5040,  5742,  6444,  7146,  7848,  8550,  9252]],\n",
       "\n",
       "       [[ 3101,  3518,  3935,  4352,  4769,  5186,  5603],\n",
       "        [ 3920,  4454,  4988,  5522,  6056,  6590,  7124],\n",
       "        [ 4739,  5390,  6041,  6692,  7343,  7994,  8645],\n",
       "        [ 5558,  6326,  7094,  7862,  8630,  9398, 10166],\n",
       "        [ 6377,  7262,  8147,  9032,  9917, 10802, 11687],\n",
       "        [ 7196,  8198,  9200, 10202, 11204, 12206, 13208]],\n",
       "\n",
       "       [[ 3997,  4534,  5071,  5608,  6145,  6682,  7219],\n",
       "        [ 5068,  5758,  6448,  7138,  7828,  8518,  9208],\n",
       "        [ 6139,  6982,  7825,  8668,  9511, 10354, 11197],\n",
       "        [ 7210,  8206,  9202, 10198, 11194, 12190, 13186],\n",
       "        [ 8281,  9430, 10579, 11728, 12877, 14026, 15175],\n",
       "        [ 9352, 10654, 11956, 13258, 14560, 15862, 17164]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_full = tensor_tt.reconstruct\n",
    "\n",
    "print(type(tensor_full))\n",
    "tensor_full.describe()\n",
    "tensor_full.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional notes on API of **Tensor** class\n",
    "\n",
    "1. In order to create a duplicate of an object of **`TensorCPD`**, **`TensorTKD`** and **`TensorTT`**  classes then use method **`copy()`**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
